{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02dff2a3",
   "metadata": {},
   "source": [
    "# Final Model Selection\n",
    "In this Notebook I will compare the three different models developed:\n",
    "1. Logistic Regression\n",
    "2. Random Forrest\n",
    "3. XGBoost\n",
    "\n",
    "I will use the best parameters selected in the previous Notebooks to train each model and choose the one that has an overall best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f8f16",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b745149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf3c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447ce8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/heart_disease/heart_2020_cleaned.csv')\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "numerical = list(df.dtypes[df.dtypes == 'float'].index.values)\n",
    "categorical = list(df.dtypes[df.dtypes == 'object'].index.values)\n",
    "categorical.remove('heartdisease')\n",
    "\n",
    "for c in categorical:\n",
    "    df[c] = df[c].str.lower()\n",
    "\n",
    "df['heartdisease'] = df['heartdisease'].str.lower()\n",
    "\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.20, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "y_train = (df_train['heartdisease']=='yes').astype('int').values\n",
    "y_val = (df_val['heartdisease']=='yes').astype('int').values\n",
    "y_test = (df_test['heartdisease']=='yes').astype('int').values\n",
    "\n",
    "df_train = df_train.drop(columns='heartdisease')\n",
    "df_val = df_val.drop(columns='heartdisease')\n",
    "df_test = df_test.drop(columns='heartdisease')\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train = dv.fit_transform(df_train.to_dict(orient='records'))\n",
    "X_val = dv.transform(df_val.to_dict(orient='records'))\n",
    "X_test = dv.transform(df_test.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082ef02",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53549021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90fb2288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8431243906754589"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=1, max_iter=10000, C=0.1)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24e12c1",
   "metadata": {},
   "source": [
    "## 2. Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe2e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7786d2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8406213565558842"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator = 300\n",
    "best_depth = 15\n",
    "best_min_samples_leaf = 4\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=best_estimator,\n",
    "                            max_depth=best_depth, \n",
    "                            min_samples_leaf=best_min_samples_leaf, \n",
    "                            random_state=1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8783d011",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a470c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc8ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(dv.get_feature_names_out())\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train, feature_names=feature_names)\n",
    "\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c66fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_eta = 0.01\n",
    "best_max_depth = 6\n",
    "best_min_child_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060383f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'eta':best_eta,\n",
    "             'max_depth':best_max_depth,\n",
    "             'min_child_weight':best_min_child_weights,\n",
    "              \n",
    "             'objective':'binary:logistic',\n",
    "             'nthread':8,\n",
    "              'eval_metric':'auc',\n",
    "              \n",
    "             'seed':1,\n",
    "             'verbosity':1}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b891706",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f8910b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8456598354472225"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e20f7c4",
   "metadata": {},
   "source": [
    "# 4 . Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d42e375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_vectorizer.bin', 'wb') as file:\n",
    "    pkl.dump(dv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445a2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logistic_regression.bin', 'wb') as file:\n",
    "    pkl.dump(lr, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "012ffb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_forrest.bin', 'wb') as file:\n",
    "    pkl.dump(rf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe5874dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgboost.bin', 'wb') as file:\n",
    "    pkl.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb2e693",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Based on results all three models had almost same AUC, therefore I decided to use the logistic regression model because it is simpler to explain and understand when looking at dependencies between variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
